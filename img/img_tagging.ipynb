{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e14c6c-ae2e-46f1-8346-42e1255b99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag list styles\n",
    "# Generate image description for Stable Diffusion LoRA training in a list of general tag.\n",
    "# List the lowercase tags in order of importance in explaining the image at least 10 tags.\n",
    "# It is better if the color characteristics are revealed on the tag.\n",
    "# (replace '_' to space and ommit the '#', do not mention background-related tags.)\n",
    "# example: tag1, tag2, tag3, tag4, ....\n",
    "\n",
    "# descriptions\n",
    "# Generate image description for Stable Diffusion LoRA training\n",
    "# The description must be written within 70 tokens without any further explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d75db-d880-402e-ae53-d69acd1610da",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"TAG\" : (\n",
    "        \"Generate image description tags for Stable Diffusion LoRA training like Danbooru style.\\n\"\n",
    "        \"Please create a tag according to the procedure below.\\n\"\n",
    "        \"1. Please make the tags specific and concise.\\n\"\n",
    "        \"2. Avoid words with overlapping meanings.\\n\"\n",
    "        \"3. Describe the subject, style, environment, lighting, color, mood, and composition.\\n\"\n",
    "        \"4. Please write with specific numbers or collective nouns.\\n\\n\"\n",
    "        \"Output must follow the format below without any further explanation.\\n\"\n",
    "        \"tag1, tag2, tag3, tag4, ....\"\n",
    "    ),\n",
    "\n",
    "    \"LINE\" : (\n",
    "        \"Generate image description for Stable Diffusion 1.5v LoRA training.\\n\"\n",
    "        \"If the sentence is long, separate it with commas so that each component can be clearly seen.\\n\" \n",
    "        \"Please write the description so that the subject, style, color, mood and composition are clearly conveyed. (Describing the composition is especially important.)\\n\"\n",
    "        \"It should be detailed and concise, avoiding words with overlapping meanings.\\n\"\n",
    "        \"Furthemore, sentence with specific numbers or collective nouns is better.\\n\"\n",
    "        \"Place the sentences you think are more important in expressing the photo forward in order.\\n\"\n",
    "        \"The description must be written within simple 70 tokens without any further explanation.\\n\\n\"\n",
    "\n",
    "        \"ex) A cute cat with big eyes, sitting on a bench, relaxed, and yawning, ...\"\n",
    "    )\n",
    "}\n",
    "print(PROMPT_DICT['LINE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9824af-e7ab-4dc0-bc8a-cbcc0b51160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageChops, Image\n",
    "\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "import io\n",
    "\n",
    "def png2rgb(img_path):\n",
    "    \n",
    "    # white background\n",
    "    \n",
    "    rgba_image = Image.open(img_path)\n",
    "    rgb_im = rgba_image.convert('RGB')\n",
    "    \n",
    "    background = Image.new(\"RGB\", rgb_im.size, (255, 255, 255))\n",
    "    \n",
    "    # 알파 채널을 이용해 이미지를 배경과 혼합\n",
    "    rgb_image = Image.alpha_composite(background.convert(\"RGBA\"), rgba_image).convert(\"RGB\")\n",
    "\n",
    "    return rgb_image\n",
    "\n",
    "def decode_img(rgb_image):\n",
    "    \n",
    "    # 메모리에서 파일처럼 처리하기 위해 BytesIO 객체 생성\n",
    "    buffered = io.BytesIO()\n",
    "    \n",
    "    # 이미지를 원하는 포맷으로 저장 (예: PNG, JPEG 등)\n",
    "    rgb_image.save(buffered, format=\"PNG\")\n",
    "    \n",
    "    # BytesIO 객체의 내용을 base64로 인코딩\n",
    "    base64_image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    \n",
    "    return base64_image\n",
    "\n",
    "def generate_description(base64_image, prompt_type=\"LINE\", additional_tags=[\"kbank-inspired style\"]):\n",
    "    \n",
    "    # OpenAI API Key\n",
    "    api_key = \"\"\n",
    "\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4o\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": PROMPT_DICT[prompt_type]\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    description = response.json()['choices'][0]['message']['content']\n",
    "    \n",
    "    additional_tags_str = \", \".join(additional_tags)\n",
    "    \n",
    "    description = additional_tags_str + \", \" + description\n",
    "    description = description.lower()\n",
    "    description = description.replace('_', \" \")\n",
    "    description = description.replace('.', \"\")\n",
    "    \n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4fb2bb-ec10-492b-a397-497427f1b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sample\n",
    "test_img = \"sample.png\"\n",
    "\n",
    "rgb_image = png2rgb(test_img)\n",
    "base64_image = decode_img(rgb_image)\n",
    "description = generate_description(base64_image, prompt_type=\"LINE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a21698-fcc4-4251-9a18-85498c79d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_nms = os.listdir(\"FULL_3D_IMAGES\")\n",
    "img_nms = [img_nm for img_nm in img_nms if img_nm.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b356e3-51bd-426e-8360-8ac9ca0d046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_dir = \"detailed_prompt\"\n",
    "img_nms = os.listdir(\"FULL_3D_IMAGES\")\n",
    "img_nms = [img_nm for img_nm in img_nms if img_nm.endswith('.png')]\n",
    "\n",
    "for img_nm in tqdm(img_nms[560:]):\n",
    "    \n",
    "    img_path = f\"FULL_3D_IMAGES/{img_nm}\"\n",
    "    \n",
    "    rgb_image = png2rgb(img_path)\n",
    "    base64_image = decode_img(rgb_image)\n",
    "    description = generate_description(base64_image, prompt_type=\"LINE\")\n",
    "\n",
    "    file_nm = img_nm.split(\".\")[0]\n",
    "    rgb_image_path = f\"{new_dir}/{file_nm}.jpg\"\n",
    "    description_path = f\"{new_dir}/{file_nm}.txt\"\n",
    "    \n",
    "    # rgb img (jpg)\n",
    "    rgb_image.save(rgb_image_path)\n",
    "\n",
    "    # write description\n",
    "    with open(description_path, \"w\") as f:\n",
    "        f.write(description)\n",
    "        \n",
    "    time.sleep(0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
